{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c1cb34",
   "metadata": {},
   "source": [
    "# MSA 2024 Phase 2 - Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aa5f79",
   "metadata": {},
   "source": [
    "Welcome to the competition - in Part 3, you are encouraged to utilize neural network based models for classification.\n",
    "\n",
    "This notebook builds a simple Multi-Layer Perceptron (MLP) model for the CIFAR-10 dataset, with the use of `keras` to define the model structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f1c5d8",
   "metadata": {},
   "source": [
    "**Before start working on the competition, please ensure all required libraries are installed and properly set up on your system**:\n",
    "\n",
    "- `python >= 3.6`,\n",
    "- `tensorFlow >= 2.0`,\n",
    "- `keras >= 2.3`,\n",
    "\n",
    "and any neccassary liburaries for data manipulation and processing, e.g., `numpy`, `pandas`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc85f3a2",
   "metadata": {},
   "source": [
    "### 1. Data loading & preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49efe468",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset contains 60,000 images(32x32x3) in 10 different classes, with 6,000 images in each class. You can download the dataset directly from the competition webpage.\n",
    "\n",
    "**To train the model, you are expected to use the training label provided in train.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49d0bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "def loadTrain(root_dir, csv_file):\n",
    "    ids = []\n",
    "    images = []\n",
    "    labels = []\n",
    "    annotations = np.genfromtxt('train.csv', delimiter=',', names=True)\n",
    "    for idx in range(len(annotations)):\n",
    "        img_id = int(annotations['id'][idx])\n",
    "        img_name = os.path.join(root_dir, f\"image_{img_id}.png\")\n",
    "        image = np.array(Image.open(img_name).convert(\"RGB\"))\n",
    "        label = int(annotations['label'][idx])\n",
    "\n",
    "        ids.append(img_id)\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "    return np.array(ids), np.array(images), np.array(labels)\n",
    "\n",
    "def loadTest(root_dir):\n",
    "    ids = []\n",
    "    images = []\n",
    "    for idx in range(len(os.listdir(root_dir))):\n",
    "        img_name = os.path.join(root_dir, f\"image_{idx}.png\")\n",
    "        image = np.array(Image.open(img_name).convert(\"RGB\"))\n",
    "\n",
    "        ids.append(idx)\n",
    "        images.append(image)\n",
    "    return np.array(ids), np.array(images)\n",
    "\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "# Load training, testing data and the training label provided in train.csv.\n",
    "train_csv = 'train.csv'\n",
    "id_train, X_train, y_train = loadTrain(train_dir, train_csv)\n",
    "id_test, X_test = loadTest(test_dir)\n",
    "\n",
    "# Normalize the data. Reshape the data to fit in to an MLP model.\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "X_train = X_train.reshape(-1, 32, 32, 3)  # -1 表示自动计算批量大小\n",
    "X_test = X_test.reshape(-1, 32, 32, 3)\n",
    "# Convert training labels to one-hot encoded vectors.\n",
    "y_train = to_categorical(y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ae9e8",
   "metadata": {},
   "source": [
    "### 2. Build & train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3f0331",
   "metadata": {},
   "source": [
    "This code demostrates a simple Multi-Layer Perceptron (MLP) model. However, you are encouraged to experiment with more complex deep learning models and techniques to boost your performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92d60add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 122,570\n",
      "Trainable params: 122,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 19s 11ms/step - loss: 1.9011 - accuracy: 0.2882 - val_loss: 1.6386 - val_accuracy: 0.4059\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 1.5472 - accuracy: 0.4359 - val_loss: 1.4079 - val_accuracy: 0.4928\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 1.4045 - accuracy: 0.4947 - val_loss: 1.4120 - val_accuracy: 0.4929\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.3012 - accuracy: 0.5355 - val_loss: 1.2963 - val_accuracy: 0.5393\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 18s 15ms/step - loss: 1.2368 - accuracy: 0.5584 - val_loss: 1.2307 - val_accuracy: 0.5631\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 1.1679 - accuracy: 0.5854 - val_loss: 1.1979 - val_accuracy: 0.5756\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.1177 - accuracy: 0.6037 - val_loss: 1.1417 - val_accuracy: 0.6017\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.0812 - accuracy: 0.6172 - val_loss: 1.1619 - val_accuracy: 0.5895\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 1.0387 - accuracy: 0.6312 - val_loss: 1.1292 - val_accuracy: 0.6043\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 1.0114 - accuracy: 0.6454 - val_loss: 1.0940 - val_accuracy: 0.6181\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "#use CNN model instead of MLP\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "# Make predictions.\n",
    "predictions = model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Prepare your submission file.\n",
    "submission = np.column_stack((id_test, predicted_labels))\n",
    "np.savetxt('submission.csv', submission, delimiter=',', header='id, Label', comments='', fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Summary\n",
    "Overview of Training and Evaluation Steps:\n",
    "\n",
    "Data Handling: Initiated by loading the image data and pre-processing it to fit the requirements of a convolutional neural network (CNN). This included normalizing the images and reshaping them for CNN compatibility.\n",
    "Model Architecture: Constructed a CNN using TensorFlow's Keras library, incorporating layers designed to capture spatial hierarchies in the images. The architecture included multiple convolutional layers, max-pooling layers to reduce dimensionality, and dense layers for classification.\n",
    "Model Training: The training process involved using Adam optimizer and categorical cross-entropy loss function. The model was trained on the available labeled data with a portion set aside as a validation set to monitor the training effectiveness and mitigate overfitting.\n",
    "Key Findings from the Process:\n",
    "\n",
    "The CNN showed consistent improvements in accuracy on the training data over the epochs, demonstrating the model's capacity to learn effectively from the dataset.\n",
    "Validation performance metrics were crucial in assessing the model’s ability to generalize, indicating that while the model performed reasonably well, there could be potential improvements to increase its robustness and accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
